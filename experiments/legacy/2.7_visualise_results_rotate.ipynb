{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import ast\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = '/Users/tania/Documents/GitHub/critical-learning-period-effect/artifacts/final_results/MNIST_variations'\n",
    "\n",
    "results = [\n",
    "    ('Bottleneck model - rotated MNIST 2.5 degrees','5_0_rotationMNIST_source2.5_target0_results.csv'),\n",
    "    ('Bottleneck model - rotated MNIST 5 degrees','5_1_rotationMNIST_source5_target0_results.csv'),\n",
    "    ('Bottleneck model - rotated MNIST 10 degrees','5_2_rotationMNIST_source10_target0_results.csv'),\n",
    "    ('Bottleneck model - rotated MNIST 40 degrees','5_3_rotationMNIST_source40_target0_results.csv'),\n",
    "    ]\n",
    "\n",
    "i = 2\n",
    "experiment_name = results[i][0]\n",
    "results_df = pd.read_csv(os.path.join(results_dir, results[i][1]))\n",
    "runs = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_curves(\n",
    "    results_df: pd.DataFrame,\n",
    "    target_eval: str = \"MNIST_hard_target\",\n",
    "    source_keywords: List[str] = [\"pretraining\"],\n",
    "    accuracy=True\n",
    "\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot learning curves (mean ± SEM) for different initialisations on a chosen evaluation set.\n",
    "    Produces two plots: one for non-source initialisations and one for source/pretraining initialisations.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame containing run histories and initial evaluation columns.\n",
    "        target_eval: Evaluation set prefix, e.g. \"MNIST_hard_target\".\n",
    "        source_keywords: Keywords used to identify pretraining/source initialisations.\n",
    "    \"\"\"\n",
    "    if accuracy:\n",
    "        acc_col = f\"{target_eval}_acc\"\n",
    "        init_acc_col = f\"initial_{target_eval}_logits_acc\"\n",
    "        label = \"Accuracy\"\n",
    "    else:\n",
    "        acc_col = f\"{target_eval}_loss\"\n",
    "        init_acc_col = f\"initial_{target_eval}_logits_loss\"\n",
    "        label = \"Loss\"\n",
    "\n",
    "    if acc_col not in results_df.columns or init_acc_col not in results_df.columns:\n",
    "        raise ValueError(f\"Required columns not found for {target_eval}: {acc_col}, {init_acc_col}\")\n",
    "\n",
    "    # Split initialisations into two groups\n",
    "    all_inits = results_df['initialisation'].unique()\n",
    "    pre_training = [init for init in all_inits if any(k.lower() in init.lower() for k in source_keywords)]\n",
    "    target_models = [init for init in all_inits if init not in pre_training]\n",
    "\n",
    "    def make_plot(sub_df, inits_to_plot, title_suffix):\n",
    "        # Aggregate over epochs\n",
    "        agg_acc = (\n",
    "            sub_df[sub_df['initialisation'].isin(inits_to_plot)]\n",
    "            .groupby(['initialisation', 'epoch'])\n",
    "            .agg(acc_mean=(acc_col, 'mean'), acc_sem=(acc_col, 'sem'))\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        # Initial accuracy row (epoch = 0)\n",
    "        per_run_init = (\n",
    "            sub_df[sub_df['initialisation'].isin(inits_to_plot)]\n",
    "            .groupby(['initialisation', 'run'])[init_acc_col]\n",
    "            .first()\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        initial_rows = (\n",
    "            per_run_init\n",
    "            .groupby('initialisation')[init_acc_col]\n",
    "            .agg(acc_mean='mean', acc_sem='sem')\n",
    "            .reset_index()\n",
    "            .assign(epoch=0)\n",
    "        )\n",
    "\n",
    "        # Combine and sort\n",
    "        agg_acc = pd.concat([initial_rows, agg_acc], ignore_index=True)\n",
    "        agg_acc = agg_acc.sort_values(['initialisation', 'epoch']).reset_index(drop=True)\n",
    "\n",
    "        # Plot\n",
    "        fig = go.Figure()\n",
    "        colors = px.colors.sample_colorscale('Viridis', np.linspace(0, 1, len(inits_to_plot)))\n",
    "        color_map = dict(zip(inits_to_plot, colors))\n",
    "\n",
    "        for init in inits_to_plot:\n",
    "            df_init = agg_acc[agg_acc['initialisation'] == init]\n",
    "            color = color_map[init]\n",
    "\n",
    "            # Mean curve\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=df_init['epoch'],\n",
    "                y=df_init['acc_mean'],\n",
    "                mode='lines',\n",
    "                name=f\"{init}<br>(final {df_init['acc_mean'].iloc[-1]:.3f} ± {df_init['acc_sem'].iloc[-1]:.3f})\",\n",
    "                line=dict(color=color, width=2)\n",
    "            ))\n",
    "\n",
    "            # SEM shading\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=df_init['epoch'].tolist() + df_init['epoch'][::-1].tolist(),\n",
    "                y=(df_init['acc_mean'] + df_init['acc_sem']).tolist() +\n",
    "                  (df_init['acc_mean'] - df_init['acc_sem'])[::-1].tolist(),\n",
    "                fill='toself',\n",
    "                fillcolor=color.replace('rgb', 'rgba').replace(')', ',0.15)'),\n",
    "                line=dict(color='rgba(255,255,255,0)'),\n",
    "                hoverinfo=\"skip\",\n",
    "                showlegend=False,\n",
    "            ))\n",
    "\n",
    "            # Individual runs\n",
    "            for source_file, df_run in sub_df[sub_df['initialisation'] == init].groupby('source'):\n",
    "                fig.add_trace(go.Scatter(\n",
    "                    x=df_run['epoch'],\n",
    "                    y=df_run[acc_col],\n",
    "                    mode='lines',\n",
    "                    line=dict(color=color, width=1),\n",
    "                    opacity=0.25,\n",
    "                    name=f'{init} - {source_file}',\n",
    "                    showlegend=False\n",
    "                ))\n",
    "\n",
    "        fig.update_layout(\n",
    "            title=f\"{i}: Performance on {experiment_name} {title_suffix} (mean ± SEM)\",\n",
    "            xaxis_title=\"Epoch\",\n",
    "            yaxis_title=f'{label} on {target_eval}',\n",
    "            template=\"plotly_white\",\n",
    "            legend_title=\"Initialisation\",\n",
    "        )\n",
    "        fig.show()\n",
    "    # Plot nonsource initialisations\n",
    "    if target_models:\n",
    "        make_plot(results_df, target_models, \"\")\n",
    "\n",
    "    # Plot source/pretraining initialisations\n",
    "    if pre_training:\n",
    "        make_plot(results_df, pre_training, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = True # Plot accuracy or loss\n",
    "\n",
    "target_eval = \"MNIST_test_target\"\n",
    "plot_accuracy_curves(results_df, target_eval=target_eval, accuracy=accuracy)\n",
    "\n",
    "target_eval = \"MNIST_hard_target\"\n",
    "plot_accuracy_curves(results_df, target_eval=target_eval, accuracy=accuracy)\n",
    "\n",
    "target_eval = \"MNIST_hard_source\"\n",
    "plot_accuracy_curves(results_df, target_eval=target_eval, accuracy=accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = [320, 350, 355, 357.5]\n",
    "test_deg = degrees[-1]\n",
    "\n",
    "target_eval =f\"MNIST_hard_{test_deg}\"\n",
    "plot_accuracy_curves(results_df, target_eval=target_eval, accuracy=accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from typing import List, Dict\n",
    "\n",
    "def plot_accuracy_curves_multi(\n",
    "    results_dict: Dict[str, pd.DataFrame],\n",
    "    target_eval: str = \"MNIST_hard_target\",\n",
    "    source_keywords: List[str] = [\"pretraining\"],\n",
    "    accuracy: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot learning curves (mean ± SEM) for different initialisations on a chosen evaluation set,\n",
    "    across multiple experiments.\n",
    "\n",
    "    Args:\n",
    "        results_dict: Dictionary mapping experiment_name -> results DataFrame\n",
    "        target_eval: Evaluation set prefix, e.g. \"MNIST_hard_target\"\n",
    "        source_keywords: Keywords used to identify pretraining/source initialisations.\n",
    "        accuracy: Whether to plot accuracy (True) or loss (False)\n",
    "    \"\"\"\n",
    "\n",
    "    if accuracy:\n",
    "        acc_col = f\"{target_eval}_acc\"\n",
    "        init_acc_col = f\"initial_{target_eval}_logits_acc\"\n",
    "        label = \"Accuracy\"\n",
    "    else:\n",
    "        acc_col = f\"{target_eval}_loss\"\n",
    "        init_acc_col = f\"initial_{target_eval}_logits_loss\"\n",
    "        label = \"Loss\"\n",
    "\n",
    "    def make_plot(sub_df, inits_to_plot, experiment_name, title_suffix):\n",
    "        # Aggregate over epochs\n",
    "        agg_acc = (\n",
    "            sub_df[sub_df['initialisation'].isin(inits_to_plot)]\n",
    "            .groupby(['initialisation', 'epoch'])\n",
    "            .agg(acc_mean=(acc_col, 'mean'), acc_sem=(acc_col, 'sem'))\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        # Initial accuracy (epoch=0)\n",
    "        per_run_init = (\n",
    "            sub_df[sub_df['initialisation'].isin(inits_to_plot)]\n",
    "            .groupby(['initialisation', 'run'])[init_acc_col]\n",
    "            .first()\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        initial_rows = (\n",
    "            per_run_init\n",
    "            .groupby('initialisation')[init_acc_col]\n",
    "            .agg(acc_mean='mean', acc_sem='sem')\n",
    "            .reset_index()\n",
    "            .assign(epoch=0)\n",
    "        )\n",
    "\n",
    "        # Combine and sort\n",
    "        agg_acc = pd.concat([initial_rows, agg_acc], ignore_index=True)\n",
    "        agg_acc = agg_acc.sort_values(['initialisation', 'epoch']).reset_index(drop=True)\n",
    "\n",
    "        # Plot\n",
    "        fig = go.Figure()\n",
    "        colors = px.colors.sample_colorscale('Viridis', np.linspace(0, 1, len(inits_to_plot)))\n",
    "        color_map = dict(zip(inits_to_plot, colors))\n",
    "\n",
    "        for init in inits_to_plot:\n",
    "            df_init = agg_acc[agg_acc['initialisation'] == init]\n",
    "            color = color_map[init]\n",
    "\n",
    "            # Mean curve\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=df_init['epoch'],\n",
    "                y=df_init['acc_mean'],\n",
    "                mode='lines',\n",
    "                name=f\"{init}<br>(final {df_init['acc_mean'].iloc[-1]:.3f} ± {df_init['acc_sem'].iloc[-1]:.3f})\",\n",
    "                line=dict(color=color, width=2)\n",
    "            ))\n",
    "\n",
    "            # SEM shading\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=df_init['epoch'].tolist() + df_init['epoch'][::-1].tolist(),\n",
    "                y=(df_init['acc_mean'] + df_init['acc_sem']).tolist() +\n",
    "                  (df_init['acc_mean'] - df_init['acc_sem'])[::-1].tolist(),\n",
    "                fill='toself',\n",
    "                fillcolor=color.replace('rgb', 'rgba').replace(')', ',0.15)'),\n",
    "                line=dict(color='rgba(255,255,255,0)'),\n",
    "                hoverinfo=\"skip\",\n",
    "                showlegend=False,\n",
    "            ))\n",
    "\n",
    "            # Individual runs\n",
    "            for source_file, df_run in sub_df[sub_df['initialisation'] == init].groupby('source'):\n",
    "                fig.add_trace(go.Scatter(\n",
    "                    x=df_run['epoch'],\n",
    "                    y=df_run[acc_col],\n",
    "                    mode='lines',\n",
    "                    line=dict(color=color, width=1),\n",
    "                    opacity=0.25,\n",
    "                    name=f'{init} - {source_file}',\n",
    "                    showlegend=False\n",
    "                ))\n",
    "\n",
    "        fig.update_layout(\n",
    "            title=f\"{experiment_name}: {target_eval} ({title_suffix})\",\n",
    "            xaxis_title=\"Epoch\",\n",
    "            yaxis_title=f'{label}',\n",
    "            template=\"plotly_white\",\n",
    "            legend_title=\"Initialisation\",\n",
    "        )\n",
    "        fig.show()\n",
    "\n",
    "    # === Main loop over experiments ===\n",
    "    for experiment_name, df in results_dict.items():\n",
    "        # Check columns exist\n",
    "        if acc_col not in df.columns or init_acc_col not in df.columns:\n",
    "            print(f\"⚠️ Skipping {experiment_name} (missing {acc_col} or {init_acc_col})\")\n",
    "            continue\n",
    "\n",
    "        all_inits = df['initialisation'].unique()\n",
    "        pre_training = [init for init in all_inits if any(k.lower() in init.lower() for k in source_keywords)]\n",
    "        target_models = [init for init in all_inits if init not in pre_training]\n",
    "\n",
    "        if target_models:\n",
    "            make_plot(df, target_models, experiment_name, \"Target-only\")\n",
    "        if pre_training:\n",
    "            make_plot(df, pre_training, experiment_name, \"Pretraining\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {\n",
    "    results[0][0]: pd.read_csv(os.path.join(results_dir, results[0][1])),\n",
    "    results[1][0]: pd.read_csv(os.path.join(results_dir, results[1][1])),\n",
    "    results[2][0]: pd.read_csv(os.path.join(results_dir, results[2][1])),\n",
    "    results[3][0]: pd.read_csv(os.path.join(results_dir, results[3][1])),\n",
    "}\n",
    "\n",
    "plot_accuracy_curves_multi(results_dict, target_eval=\"MNIST_hard_target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from typing import Dict, List\n",
    "\n",
    "def plot_combined_nonpretraining(\n",
    "    results_dict: Dict[str, pd.DataFrame],\n",
    "    target_eval: str = \"MNIST_hard_target\",\n",
    "    source_keywords: List[str] = [\"pretraining\"],\n",
    "    accuracy: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Combine all non-pretraining runs from multiple experiments into a single plot.\n",
    "    Each (experiment, initialisation) pair gets its own line.\n",
    "    \"\"\"\n",
    "    # Choose column names\n",
    "    if accuracy:\n",
    "        acc_col = f\"{target_eval}_acc\"\n",
    "        init_acc_col = f\"initial_{target_eval}_logits_acc\"\n",
    "        label = \"Accuracy\"\n",
    "    else:\n",
    "        acc_col = f\"{target_eval}_loss\"\n",
    "        init_acc_col = f\"initial_{target_eval}_logits_loss\"\n",
    "        label = \"Loss\"\n",
    "\n",
    "    # Concatenate all runs and add experiment name\n",
    "    all_dfs = []\n",
    "    for exp_name, df in results_dict.items():\n",
    "        df = df.copy()\n",
    "        df['experiment'] = exp_name\n",
    "        all_dfs.append(df)\n",
    "    big_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "    # Identify pretraining vs non-pretraining initialisations\n",
    "    all_inits = big_df['initialisation'].unique()\n",
    "    pre_training = [init for init in all_inits if any(k.lower() in init.lower() for k in source_keywords)]\n",
    "    target_models = [init for init in all_inits if init not in pre_training]\n",
    "\n",
    "    if not target_models:\n",
    "        print(\"⚠️ No non-pretraining runs found.\")\n",
    "        return\n",
    "\n",
    "    # Aggregate over runs to get mean ± SEM\n",
    "    agg_df = (\n",
    "        big_df[big_df['initialisation'].isin(target_models)]\n",
    "        .groupby(['experiment', 'initialisation', 'epoch'])\n",
    "        .agg(acc_mean=(acc_col, 'mean'), acc_sem=(acc_col, 'sem'))\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Initial accuracy rows\n",
    "    per_run_init = (\n",
    "        big_df[big_df['initialisation'].isin(target_models)]\n",
    "        .groupby(['experiment', 'initialisation', 'run'])[init_acc_col]\n",
    "        .first()\n",
    "        .reset_index()\n",
    "    )\n",
    "    initial_rows = (\n",
    "        per_run_init\n",
    "        .groupby(['experiment', 'initialisation'])[init_acc_col]\n",
    "        .agg(acc_mean='mean', acc_sem='sem')\n",
    "        .reset_index()\n",
    "        .assign(epoch=0)\n",
    "    )\n",
    "\n",
    "    agg_df = pd.concat([initial_rows, agg_df], ignore_index=True)\n",
    "    agg_df = agg_df.sort_values(['experiment', 'initialisation', 'epoch']).reset_index(drop=True)\n",
    "\n",
    "    # Build plot\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Define colors for each experiment\n",
    "    unique_experiments = agg_df['experiment'].unique()\n",
    "    colors = px.colors.sample_colorscale('Viridis', np.linspace(0, 1, len(unique_experiments)))\n",
    "    color_map = dict(zip(unique_experiments, colors))\n",
    "\n",
    "    # Line styles: dashed for random initialisation, solid otherwise\n",
    "    def get_line_style(init_name, base_color):\n",
    "        if \"random\" in init_name.lower():\n",
    "            return dict(\n",
    "                dash='dash',          # dashed line\n",
    "                width=2,              # thinner\n",
    "                color=base_color.replace('rgb', 'rgba').replace(')', ',0.6)')  # 40% opacity\n",
    "            )\n",
    "        else:\n",
    "            return dict(\n",
    "                dash='solid',\n",
    "                width=2,\n",
    "                color=base_color\n",
    "            )\n",
    "\n",
    "    # Add traces\n",
    "    for (exp_name, init), df_sub in agg_df.groupby(['experiment', 'initialisation']):\n",
    "        color = color_map[exp_name]\n",
    "\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df_sub['epoch'],\n",
    "            y=df_sub['acc_mean'],\n",
    "            mode='lines',\n",
    "            name=f\"{exp_name} — {init}\",\n",
    "            line=get_line_style(init, color)\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"4. Combined Experiment Results — models pretrained on different degrees of rotation\",\n",
    "        xaxis_title=\"Epoch\",\n",
    "        yaxis_title=f'label on {target_eval}',\n",
    "        template=\"plotly_white\",\n",
    "        legend_title=\"Experiment — Init\",\n",
    "    )\n",
    "    fig.update_layout(showlegend=False)\n",
    "    fig.show()\n",
    "\n",
    "    # Legend plot\n",
    "    legend_fig = go.Figure()\n",
    "\n",
    "    for (exp_name, init), df_sub in agg_df.groupby(['experiment', 'initialisation']):\n",
    "        color = color_map[exp_name]\n",
    "\n",
    "        # Add a single dummy point just for the legend\n",
    "        legend_fig.add_trace(go.Scatter(\n",
    "            x=[None],  # no actual points\n",
    "            y=[None],\n",
    "            mode='lines',\n",
    "            name=f\"{exp_name} — {init}\",\n",
    "            line=get_line_style(init, color)\n",
    "        ))\n",
    "\n",
    "    legend_fig.update_layout(\n",
    "        title=\"Legend\",\n",
    "        template=\"plotly_white\"\n",
    "    )\n",
    "    legend_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_combined_nonpretraining(results_dict, target_eval=\"MNIST_hard_target\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "critical-learning-period-effect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
